{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0233a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Conda\\envs\\rag_learning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, BitsAndBytesConfig, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset, concatenate_datasets, DatasetDict\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from peft import prepare_model_for_kbit_training\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "BASEPATH = os.path.dirname(os.getcwd())\n",
    "DATASETPATH = os.path.join(BASEPATH,\"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b8b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain = pd.read_csv(f\"{DATASETPATH}/train.csv\")\n",
    "datasetTest = pd.read_csv(f\"{DATASETPATH}/test.csv\")\n",
    "datasetValidation = pd.read_csv(f\"{DATASETPATH}/validation.csv\")\n",
    "\n",
    "datasetTrain = Dataset.from_pandas(datasetTrain)\n",
    "datasetTest = Dataset.from_pandas(datasetTest)\n",
    "datasetValidation = Dataset.from_pandas(datasetValidation)\n",
    "\n",
    "datasetTrain = concatenate_datasets([datasetTrain, datasetTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e5a158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'article', 'highlights'],\n",
       "        num_rows: 298603\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'article', 'highlights'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetFull = DatasetDict(\n",
    "    {\n",
    "        \"train\" : datasetTrain,\n",
    "        \"test\" : datasetTest\n",
    "    }\n",
    ")\n",
    "datasetFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56c28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train = list(range(0,298603))\n",
    "shuffled_test = list(range(0,11490))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(shuffled_train)\n",
    "random.shuffle(shuffled_train)\n",
    "random.shuffle(shuffled_test)\n",
    "random.shuffle(shuffled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a93de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetFull[\"train\"] = datasetFull[\"train\"].select(shuffled_train[:5000])\n",
    "datasetFull[\"test\"] = datasetFull[\"test\"].select(shuffled_test[:1100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf8ceb",
   "metadata": {},
   "source": [
    "## 1. T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39dda54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/flan-t5-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d7d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c1d62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Exception in thread Thread-4 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Conda\\envs\\rag_learning\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"d:\\Conda\\envs\\rag_learning\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"d:\\Conda\\envs\\rag_learning\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"d:\\Conda\\envs\\rag_learning\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb2 in position 7: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "model_tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model_base = T5ForConditionalGeneration.from_pretrained(model_name, quantization_config = quantization_config, device_map = \"auto\", torch_dtype = torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fe8e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.gradient_checkpointing_enable()\n",
    "model_base = prepare_model_for_kbit_training(model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1911c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q\", \"v\"], \n",
    "    task_type=TaskType.SEQ_2_SEQ_LM, \n",
    "    bias=\"none\"\n",
    ")\n",
    "model_base = get_peft_model(model_base, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fe9a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e03913af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5000/5000 [00:22<00:00, 226.31 examples/s]\n",
      "Map: 100%|██████████| 1100/1100 [00:05<00:00, 200.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenization(batch) : \n",
    "    question = [f\"summary : {q}\" for q in batch[\"article\"]]\n",
    "    hasil_tokenized = model_tokenizer(question, padding = \"max_length\", truncation = True, max_length = 512)\n",
    "    labels = model_tokenizer(batch[\"highlights\"], padding = \"max_length\", truncation = True, max_length = 256)\n",
    "    ignore_pad = []\n",
    "    for lab in labels[\"input_ids\"] :\n",
    "        ignore_pad.append([]) \n",
    "        for num in lab : \n",
    "            if num != model_tokenizer.pad_token_id : \n",
    "                ignore_pad[-1].append(num)\n",
    "            else : \n",
    "                ignore_pad[-1].append(-100)\n",
    "    hasil_tokenized[\"labels\"] = ignore_pad\n",
    "    return hasil_tokenized\n",
    "\n",
    "datasetFull = datasetFull.map(tokenization, batched = True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a71241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingArgs = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./hasil-training\",\n",
    "    per_device_train_batch_size=16,       # Jauh lebih aman untuk 8GB\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-4,                \n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_rougeL\", \n",
    "    greater_is_better=True,             \n",
    "    optim=\"paged_adamw_8bit\",          \n",
    "    gradient_checkpointing=True,     \n",
    "    predict_with_generate=True,         \n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37eb2e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load metrik ROUGE\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    \n",
    "    # Jika preds adalah tuple, ambil elemen pertama\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "        \n",
    "    # Decode prediksi menjadi teks\n",
    "    decoded_preds = model_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    \n",
    "    # Ganti -100 pada label agar bisa di-decode (kembalikan ke pad_token_id)\n",
    "    labels = np.where(labels != -100, labels, model_tokenizer.pad_token_id)\n",
    "    decoded_labels = model_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # ROUGE butuh newline setelah setiap kalimat untuk skor yang lebih akurat\n",
    "    decoded_preds = [\"\\n\".join(p.strip().split()) for p in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(l.strip().split()) for l in decoded_labels]\n",
    "\n",
    "    # Hitung skor ROUGE\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    \n",
    "    # Ambil skor dalam persentase (0-100)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9841c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=model_tokenizer,\n",
    "    model=model_base,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=8 # Optimasi untuk GPU Tensor Cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22013d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reynaldi\\AppData\\Local\\Temp\\ipykernel_13484\\3185109899.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model_base,\n",
    "    args=trainingArgs, # Menggunakan TrainingArguments yang sudah kita bahas sebelumnya\n",
    "    train_dataset=datasetFull[\"train\"],\n",
    "    eval_dataset=datasetFull[\"test\"],\n",
    "    tokenizer=model_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66ac9527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [939/939 1:31:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.849800</td>\n",
       "      <td>1.705168</td>\n",
       "      <td>25.412000</td>\n",
       "      <td>11.952000</td>\n",
       "      <td>20.792100</td>\n",
       "      <td>25.412700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 06:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.7051680088043213,\n",
       " 'eval_rouge1': 25.412,\n",
       " 'eval_rouge2': 11.952,\n",
       " 'eval_rougeL': 20.7921,\n",
       " 'eval_rougeLsum': 25.4127,\n",
       " 'eval_runtime': 415.8947,\n",
       " 'eval_samples_per_second': 2.645,\n",
       " 'eval_steps_per_second': 0.332,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(f\"{BASEPATH}/modelAbstractive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c3dde2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe_real = pipeline(task = \"summarization\", model = model_name)\n",
    "# pipe_trained = pipeline(task = \"summarization\", model = f\"{BASEPATH}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c057eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================================\n",
    "# BEFORE DOING FINE TUNING : \n",
    "# ===================================================================================== \n",
    "\n",
    "jawaban_real = []\n",
    "jawaban_predict = []\n",
    "\n",
    "for batch in range(0,1016,16) : \n",
    "    q = datasetFull[\"test\"][\"article\"][batch:batch+16]\n",
    "    hasil = pipe_real(q, truncation = True)\n",
    "    for i in hasil : \n",
    "        jawaban_predict.append(i[\"summary_text\"])\n",
    "    jawaban_real.extend(datasetFull[\"test\"][\"highlights\"][batch:batch+16])\n",
    "    break\n",
    "\n",
    "import evaluate \n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")\n",
    "score_for_rouge = rouge_score.compute(predictions = jawaban_predict, references = jawaban_real)\n",
    "\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "score_for_bert = bertscore.compute(predictions = jawaban_predict, references=jawaban_real, lang = \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e5f037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': np.float64(0.26819049749228985),\n",
       " 'rouge2': np.float64(0.12966378944930246),\n",
       " 'rougeL': np.float64(0.19755372911598235),\n",
       " 'rougeLsum': np.float64(0.24546768159373245)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_for_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77a8806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : 85.6%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bert Score : {round(float(np.mean(score_for_bert['f1'])),3) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# AFTER DOING FINE TUNING : \n",
    "# ===================================================================================== \n",
    "\n",
    "jawaban_real = []\n",
    "jawaban_predict = []\n",
    "\n",
    "for batch in range(0,1016,16) : \n",
    "    q = datasetFull[\"test\"][\"article\"][batch:batch+16]\n",
    "    hasil = pipe_trained(q, truncation = True)\n",
    "    for i in hasil : \n",
    "        jawaban_predict.append(i[\"summary_text\"])\n",
    "    jawaban_real.extend(datasetFull[\"test\"][\"highlights\"][batch:batch+16])\n",
    "    break\n",
    "\n",
    "import evaluate \n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")\n",
    "score_for_rouge = rouge_score.compute(predictions = jawaban_predict, references = jawaban_real)\n",
    "\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "score_for_bert = bertscore.compute(predictions = jawaban_predict, references=jawaban_real, lang = \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a563ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': np.float64(0.3858755621784705),\n",
       " 'rouge2': np.float64(0.17576210771150474),\n",
       " 'rougeL': np.float64(0.2826192216294863),\n",
       " 'rougeLsum': np.float64(0.32857307755883425)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_for_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ca0d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : 88.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bert Score : {round(float(np.mean(score_for_bert['f1'])),3) * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
